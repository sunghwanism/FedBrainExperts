{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "from src.simulator.utils import generate_model, get_client_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path, proj_name):\n",
    "    PATH = os.path.join(config_path, f\"config_{proj_name}.json\")\n",
    "    with open(PATH, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    return config\n",
    "\n",
    "def load_model(model_name, modelPATH, config, device):\n",
    "    # device = torch.device('cpu')\n",
    "    PATH = os.path.join(modelPATH, model_name)\n",
    "    model_dict = torch.load(PATH, map_location=device)\n",
    "\n",
    "    global_model = generate_model(config).to(device)\n",
    "    \n",
    "    if (config.agg_method != \"Center\") and (config.agg_method != \"Local\"):\n",
    "        global_model.load_state_dict(model_dict['global_model'], strict=False)\n",
    "        local_model_dict = model_dict['local_model']\n",
    "        \n",
    "    else:\n",
    "        global_model.load_state_dict(model_dict['model'], strict=False)\n",
    "        local_model_dict = None\n",
    "\n",
    "    return global_model, local_model_dict\n",
    "\n",
    "def load_model(model_name, modelPATH, config, device):\n",
    "    # device = torch.device('cpu')\n",
    "    PATH = os.path.join(modelPATH, model_name)\n",
    "    model_dict = torch.load(PATH, map_location=device)\n",
    "\n",
    "    global_model = generate_model(config).to(device)\n",
    "    \n",
    "    if (config.agg_method != \"Center\") and (config.agg_method != \"Local\"):\n",
    "        global_model.load_state_dict(model_dict['global_model'], strict=False)\n",
    "        local_model_dict = model_dict['local_model']\n",
    "        \n",
    "    else:\n",
    "        global_model.load_state_dict(model_dict['model'], strict=False)\n",
    "        local_model_dict = None\n",
    "\n",
    "    return global_model, local_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePATH = \"Z://Users/moonsh/AdaptFL/ckpt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type_dict = {\"Center\": [\"generous-sunset-1\", -1], # No need to specify epoch\n",
    "                   \"Local\": [\"good-surf-1\", -1], # No need to specify epoch\n",
    "                   \"FedAvg\" : [\"polished-wood-3\", -1],\n",
    "                   \"FedProx\": [\"spring-sponge-10\", -1],  \n",
    "                   \"MOON\": [\"fancy-disco-2\", -1]\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_method = \"FedAvg\"\n",
    "wandb_name = model_type_dict[agg_method][0]\n",
    "client_idx = 8\n",
    "\n",
    "\n",
    "ckptPATH = os.path.join(basePATH, agg_method, wandb_name)\n",
    "config = load_config(ckptPATH, wandb_name)\n",
    "config['batch_size'] = 32\n",
    "config['num_workers'] = 2\n",
    "config['nowandb'] = True\n",
    "config = argparse.Namespace(**config)\n",
    "\n",
    "model_name = f'{wandb_name}_best_model.pth'\n",
    "glob_model = load_model(model_name, ckptPATH, config, torch.device('cpu'))\n",
    "local_weight = glob_model[1][client_idx]\n",
    "\n",
    "glob_model = glob_model[0]\n",
    "# local_model = deepcopy(glob_model)\n",
    "# local_model.load_state_dict(local_model, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestDataset = get_client_dataset(config, 10, \n",
    "                                 'Test', verbose=False, \n",
    "                                 get_info=False, PATH='Z://Users/moonsh/data/FLData/')\n",
    "\n",
    "client_dataset = TestDataset[client_idx]\n",
    "dataloader = DataLoader(client_dataset, batch_size=len(client_dataset))\n",
    "\n",
    "full_batch_dataset = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = deepcopy(glob_model)\n",
    "local_model.load_state_dict(local_weight, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation={'Local': {},\n",
    "            'Global': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(model_name, layer_name):\n",
    "    def hook(module, input, output):\n",
    "        activation[model_name][layer_name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "\n",
    "def register_hooks_for_model(model, model_name):\n",
    "    hooks = []\n",
    "    for name, layer in model.named_modules():\n",
    "        if (isinstance(layer, nn.Conv3d) or isinstance(layer, nn.Linear)) and ('downsample' not in name):\n",
    "            hook = layer.register_forward_hook(get_activation(model_name, name))\n",
    "            hooks.append(hook)\n",
    "    return hooks\n",
    "\n",
    "def remove_hooks(hooks):\n",
    "    for hook in hooks:\n",
    "        hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hooks_model_a = register_hooks_for_model(local_model, 'Local')\n",
    "hooks_model_b = register_hooks_for_model(glob_model, 'Global')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_rep = local_model(full_batch_dataset[0]) # predict 값\n",
    "glob_rep = glob_model(full_batch_dataset[0]) # predict 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 0\n",
    "for (layer_name, loc_output), glob_output in zip(activation['Local'].items(), activation['Global'].values()):\n",
    "    print(layer_name, loc_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_show_ch = 16\n",
    "interval_ch = channel // num_show_ch\n",
    "channel_index_list = [i for i in range(0, channel, interval_ch)]\n",
    "len(channel_index_list)\n",
    "\n",
    "if len(channel_index_list) > num_show_ch:\n",
    "    channel_index_list = channel_index_list[:num_show_ch]\n",
    "len(channel_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = loc_output\n",
    "activations2 = glob_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4, figsize=(16, 16))\n",
    "\n",
    "for plot_idx, i in enumerate(channel_index_list):\n",
    "    ax = axs[plot_idx // 4, plot_idx % 4]\n",
    "\n",
    "    channel_activations = activations[:, i, :, :, :].flatten()\n",
    "    channel_activations2 = activations2[:, i, :, :, :].flatten()\n",
    "\n",
    "    # Kernel Density Estimation\n",
    "    kde = gaussian_kde(channel_activations)\n",
    "    activation_range = np.linspace(channel_activations.min(), channel_activations.max(), 100)\n",
    "    kde_values = kde(activation_range)\n",
    "\n",
    "    kde2 = gaussian_kde(channel_activations2)\n",
    "    activation_range2 = np.linspace(channel_activations2.min(), channel_activations2.max(), 100)\n",
    "    kde_values2 = kde2(activation_range2)\n",
    "\n",
    "    # Plot KDE\n",
    "    ax.plot(activation_range, kde_values, color='red', label='Local')\n",
    "    ax.plot(activation_range2, kde_values2, color='blue', label='FedAvg')\n",
    "    ax.set_title('KDE of Activations (Channel {})'.format(i))\n",
    "    ax.set_xlabel('Activation Value')\n",
    "    ax.set_ylabel('Probability Density')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "remove_hooks(hooks_model_a)\n",
    "remove_hooks(hooks_model_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AdaptFL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
