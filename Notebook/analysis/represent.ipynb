{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import argparse\n",
    "\n",
    "import pandas as pandas\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import load_config, load_model, get_representation_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representation_hook(name):\n",
    "    def hook(model, input, output):\n",
    "        representations[name] = output.detach()\n",
    "\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_method = 'FedProx'\n",
    "proj_name = 'dashing-gorge-7'\n",
    "ckptPATH = f'/NFS/Users/moonsh/AdaptFL/ckpt/{agg_method}/' # 'Z://Users/moonsh/AdaptFL/ckpt'\n",
    "\n",
    "config = load_config(ckptPATH, proj_name)\n",
    "config['batch_size'] = 64\n",
    "config['num_workers'] = 4\n",
    "config['nowandb'] = True\n",
    "\n",
    "config = argparse.Namespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_name = proj_name.split('-')[1]\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "model_name = 'dashing-gorge-7_best_round_048.pth'\n",
    "glob_model, loc_model_dict = load_model(model_name, ckptPATH, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in glob_model.named_parameters():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = {}\n",
    "glob_model.layer1.register_forward_hook(get_representation_hook('layer1'))\n",
    "glob_model.layer2.register_forward_hook(get_representation_hook('layer2'))\n",
    "glob_model.layer3.register_forward_hook(get_representation_hook('layer3'))\n",
    "glob_model.layer4.register_forward_hook(get_representation_hook('layer4'))\n",
    "glob_model.fc.register_forward_hook(get_representation_hook('fc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn(1, 1, 96, 128, 96).to(device)\n",
    "with torch.no_grad():\n",
    "    output = glob_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer, rep in representations.items():\n",
    "    print(f\"Representation from {layer}: {rep.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AdaptFL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
